{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Turn nuclear and non nuclear protein sequences into feature vectors of size n=20 using pssm"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1710602897894,"user":{"displayName":"Ming Zhang","userId":"10190553885349216985"},"user_tz":420},"id":"2KPJOX0vzzwB"},"outputs":[],"source":["from collections import defaultdict\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","\n","import sys\n","sys.path.insert(0, './src')\n","from pssm_scoring import *"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Find the top n scores\n","def compute_top_n_scores(array, length=20):\n","    top_n = np.partition(array, -length)[-length:]\n","    top_n_sorted = np.sort(top_n)[::-1]  # Sort and reverse to show largest first\n","    return top_n_sorted"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# Remove sequences that contain unknown aa\n","standard_amino_acids = 'ACDEFGHIKLMNPQRSTVWY'  # 20 standard amino acids\n","def remove_sequences(df, column_name):\n","    remove_index = []\n","    for i,seq in enumerate(df[column_name]):\n","        if any(aa not in standard_amino_acids for aa in seq):\n","            remove_index.append(i)\n","\n","    return df.drop(df.index[remove_index])\n","\n","def remove_short_sequences(df, length_cutoff):\n","    return df[df['Length'] >= length_cutoff]"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# Create a DataFrame from the list of top n scores and label\n","def create_feature_vectors(df, pssm, column_name, feature_vec_length, label ):\n","    top_n_scores_list = [compute_top_n_scores(pssm.calculate(protein_seq),feature_vec_length) for protein_seq in df[column_name]]\n","    scores_df = pd.DataFrame(top_n_scores_list, columns=[f'Score_{i+1}' for i in range(feature_vec_length)])\n","    scores_df['Label'] = label\n","    return scores_df\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["# Load the nuclear pssm from the file\n","with open('data/nls_pssm.pkl', 'rb') as f:\n","    nls_pssm = pickle.load(f)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Load nuclear and non-nuclear protein sequences\n","nuclear_protein_df = pd.read_csv('data/data_NLS.csv')\n","non_nuclear_proteins_df = pd.read_csv('data/data_non_nuclear_proteins.csv')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Define the length of the feature vectors\n","feature_vec_length = 20\n","length_cutoff = feature_vec_length + 20"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Clean data\n","nuclear_protein_df_cleaned = remove_sequences(nuclear_protein_df,'Sequence_y')\n","non_nuclear_proteins_df_cleaned = remove_short_sequences(remove_sequences(non_nuclear_proteins_df, 'Sequence'),length_cutoff)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# Create nuclear and non-nuclear feature vectors with labels\n","NLS_feature_df = create_feature_vectors(nuclear_protein_df_cleaned,nls_pssm, 'Sequence_y',feature_vec_length, 1)\n","non_NLS_feature_df = create_feature_vectors(non_nuclear_proteins_df_cleaned,nls_pssm, 'Sequence', feature_vec_length, 0)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Score_1</th>\n","      <th>Score_2</th>\n","      <th>Score_3</th>\n","      <th>Score_4</th>\n","      <th>Score_5</th>\n","      <th>Score_6</th>\n","      <th>Score_7</th>\n","      <th>Score_8</th>\n","      <th>Score_9</th>\n","      <th>Score_10</th>\n","      <th>...</th>\n","      <th>Score_12</th>\n","      <th>Score_13</th>\n","      <th>Score_14</th>\n","      <th>Score_15</th>\n","      <th>Score_16</th>\n","      <th>Score_17</th>\n","      <th>Score_18</th>\n","      <th>Score_19</th>\n","      <th>Score_20</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1170</th>\n","      <td>5.141886</td>\n","      <td>4.724116</td>\n","      <td>3.683609</td>\n","      <td>3.546735</td>\n","      <td>2.712349</td>\n","      <td>2.262280</td>\n","      <td>2.219584</td>\n","      <td>1.770030</td>\n","      <td>1.181785</td>\n","      <td>1.135787</td>\n","      <td>...</td>\n","      <td>0.747513</td>\n","      <td>0.521171</td>\n","      <td>0.234614</td>\n","      <td>0.108036</td>\n","      <td>0.089892</td>\n","      <td>-0.170862</td>\n","      <td>-0.392231</td>\n","      <td>-0.749415</td>\n","      <td>-0.807705</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>118</th>\n","      <td>4.058798</td>\n","      <td>1.693560</td>\n","      <td>1.621346</td>\n","      <td>1.299358</td>\n","      <td>1.095644</td>\n","      <td>0.844506</td>\n","      <td>0.821500</td>\n","      <td>0.713321</td>\n","      <td>0.495712</td>\n","      <td>-0.366810</td>\n","      <td>...</td>\n","      <td>-0.995496</td>\n","      <td>-1.196517</td>\n","      <td>-1.310946</td>\n","      <td>-1.346947</td>\n","      <td>-1.372618</td>\n","      <td>-1.468269</td>\n","      <td>-1.548270</td>\n","      <td>-1.801031</td>\n","      <td>-1.844818</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>9.118779</td>\n","      <td>6.277234</td>\n","      <td>6.016829</td>\n","      <td>5.968548</td>\n","      <td>5.509716</td>\n","      <td>5.458274</td>\n","      <td>4.329693</td>\n","      <td>4.247753</td>\n","      <td>4.035923</td>\n","      <td>3.515393</td>\n","      <td>...</td>\n","      <td>3.037692</td>\n","      <td>2.706254</td>\n","      <td>2.557700</td>\n","      <td>2.546307</td>\n","      <td>2.505921</td>\n","      <td>2.198168</td>\n","      <td>2.046007</td>\n","      <td>1.845421</td>\n","      <td>1.829200</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1000</th>\n","      <td>11.004908</td>\n","      <td>9.298845</td>\n","      <td>8.020465</td>\n","      <td>7.322304</td>\n","      <td>5.919030</td>\n","      <td>5.633911</td>\n","      <td>5.140097</td>\n","      <td>4.920547</td>\n","      <td>4.852774</td>\n","      <td>4.217218</td>\n","      <td>...</td>\n","      <td>3.759845</td>\n","      <td>3.251276</td>\n","      <td>2.708628</td>\n","      <td>2.406480</td>\n","      <td>2.201303</td>\n","      <td>1.982353</td>\n","      <td>1.918615</td>\n","      <td>1.916733</td>\n","      <td>1.903443</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>899</th>\n","      <td>24.906069</td>\n","      <td>23.218674</td>\n","      <td>22.737000</td>\n","      <td>22.333403</td>\n","      <td>18.150452</td>\n","      <td>17.886356</td>\n","      <td>17.237713</td>\n","      <td>15.608488</td>\n","      <td>14.106956</td>\n","      <td>14.028743</td>\n","      <td>...</td>\n","      <td>13.140636</td>\n","      <td>12.696486</td>\n","      <td>12.556838</td>\n","      <td>9.502391</td>\n","      <td>9.047017</td>\n","      <td>8.617747</td>\n","      <td>8.589288</td>\n","      <td>6.926116</td>\n","      <td>6.421696</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["        Score_1    Score_2    Score_3    Score_4    Score_5    Score_6  \\\n","1170   5.141886   4.724116   3.683609   3.546735   2.712349   2.262280   \n","118    4.058798   1.693560   1.621346   1.299358   1.095644   0.844506   \n","96     9.118779   6.277234   6.016829   5.968548   5.509716   5.458274   \n","1000  11.004908   9.298845   8.020465   7.322304   5.919030   5.633911   \n","899   24.906069  23.218674  22.737000  22.333403  18.150452  17.886356   \n","\n","        Score_7    Score_8    Score_9   Score_10  ...   Score_12   Score_13  \\\n","1170   2.219584   1.770030   1.181785   1.135787  ...   0.747513   0.521171   \n","118    0.821500   0.713321   0.495712  -0.366810  ...  -0.995496  -1.196517   \n","96     4.329693   4.247753   4.035923   3.515393  ...   3.037692   2.706254   \n","1000   5.140097   4.920547   4.852774   4.217218  ...   3.759845   3.251276   \n","899   17.237713  15.608488  14.106956  14.028743  ...  13.140636  12.696486   \n","\n","       Score_14  Score_15  Score_16  Score_17  Score_18  Score_19  Score_20  \\\n","1170   0.234614  0.108036  0.089892 -0.170862 -0.392231 -0.749415 -0.807705   \n","118   -1.310946 -1.346947 -1.372618 -1.468269 -1.548270 -1.801031 -1.844818   \n","96     2.557700  2.546307  2.505921  2.198168  2.046007  1.845421  1.829200   \n","1000   2.708628  2.406480  2.201303  1.982353  1.918615  1.916733  1.903443   \n","899   12.556838  9.502391  9.047017  8.617747  8.589288  6.926116  6.421696   \n","\n","      Label  \n","1170      1  \n","118       1  \n","96        1  \n","1000      1  \n","899       1  \n","\n","[5 rows x 21 columns]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["NLS_feature_df.sample(5)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Score_1</th>\n","      <th>Score_2</th>\n","      <th>Score_3</th>\n","      <th>Score_4</th>\n","      <th>Score_5</th>\n","      <th>Score_6</th>\n","      <th>Score_7</th>\n","      <th>Score_8</th>\n","      <th>Score_9</th>\n","      <th>Score_10</th>\n","      <th>...</th>\n","      <th>Score_12</th>\n","      <th>Score_13</th>\n","      <th>Score_14</th>\n","      <th>Score_15</th>\n","      <th>Score_16</th>\n","      <th>Score_17</th>\n","      <th>Score_18</th>\n","      <th>Score_19</th>\n","      <th>Score_20</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>48421</th>\n","      <td>7.557083</td>\n","      <td>6.647229</td>\n","      <td>5.341608</td>\n","      <td>5.119096</td>\n","      <td>4.808097</td>\n","      <td>4.502225</td>\n","      <td>3.100829</td>\n","      <td>3.037402</td>\n","      <td>2.926094</td>\n","      <td>2.333342</td>\n","      <td>...</td>\n","      <td>1.782180</td>\n","      <td>1.739136</td>\n","      <td>1.282862</td>\n","      <td>1.043963</td>\n","      <td>1.038223</td>\n","      <td>0.876496</td>\n","      <td>0.739709</td>\n","      <td>0.703845</td>\n","      <td>0.416444</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>60415</th>\n","      <td>1.679797</td>\n","      <td>-1.127315</td>\n","      <td>-1.696114</td>\n","      <td>-2.168103</td>\n","      <td>-2.176711</td>\n","      <td>-2.530419</td>\n","      <td>-2.650950</td>\n","      <td>-2.738926</td>\n","      <td>-2.870982</td>\n","      <td>-3.215358</td>\n","      <td>...</td>\n","      <td>-3.523700</td>\n","      <td>-3.791667</td>\n","      <td>-3.841980</td>\n","      <td>-3.857994</td>\n","      <td>-4.071139</td>\n","      <td>-4.082572</td>\n","      <td>-4.095625</td>\n","      <td>-4.100740</td>\n","      <td>-4.364736</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>33898</th>\n","      <td>1.113741</td>\n","      <td>0.625018</td>\n","      <td>0.500162</td>\n","      <td>0.234711</td>\n","      <td>-0.197442</td>\n","      <td>-0.417494</td>\n","      <td>-0.451419</td>\n","      <td>-0.628390</td>\n","      <td>-1.510631</td>\n","      <td>-1.655857</td>\n","      <td>...</td>\n","      <td>-2.012618</td>\n","      <td>-2.378323</td>\n","      <td>-2.555069</td>\n","      <td>-2.573125</td>\n","      <td>-2.627829</td>\n","      <td>-2.725794</td>\n","      <td>-2.778367</td>\n","      <td>-2.857371</td>\n","      <td>-2.917282</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23978</th>\n","      <td>10.813778</td>\n","      <td>8.499226</td>\n","      <td>8.227059</td>\n","      <td>6.469109</td>\n","      <td>5.334997</td>\n","      <td>5.008693</td>\n","      <td>4.558183</td>\n","      <td>3.993275</td>\n","      <td>3.471257</td>\n","      <td>3.449827</td>\n","      <td>...</td>\n","      <td>2.835068</td>\n","      <td>2.704193</td>\n","      <td>2.618517</td>\n","      <td>2.594410</td>\n","      <td>2.519485</td>\n","      <td>2.493372</td>\n","      <td>2.471543</td>\n","      <td>2.318758</td>\n","      <td>2.287037</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2086</th>\n","      <td>-3.281637</td>\n","      <td>-3.783387</td>\n","      <td>-3.820870</td>\n","      <td>-4.281095</td>\n","      <td>-4.782397</td>\n","      <td>-4.866241</td>\n","      <td>-5.004274</td>\n","      <td>-5.531252</td>\n","      <td>-5.750714</td>\n","      <td>-5.792025</td>\n","      <td>...</td>\n","      <td>-6.427528</td>\n","      <td>-6.855747</td>\n","      <td>-7.284554</td>\n","      <td>-7.872125</td>\n","      <td>-8.144029</td>\n","      <td>-9.092268</td>\n","      <td>-9.120149</td>\n","      <td>-9.344419</td>\n","      <td>-9.404174</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"],"text/plain":["         Score_1   Score_2   Score_3   Score_4   Score_5   Score_6   Score_7  \\\n","48421   7.557083  6.647229  5.341608  5.119096  4.808097  4.502225  3.100829   \n","60415   1.679797 -1.127315 -1.696114 -2.168103 -2.176711 -2.530419 -2.650950   \n","33898   1.113741  0.625018  0.500162  0.234711 -0.197442 -0.417494 -0.451419   \n","23978  10.813778  8.499226  8.227059  6.469109  5.334997  5.008693  4.558183   \n","2086   -3.281637 -3.783387 -3.820870 -4.281095 -4.782397 -4.866241 -5.004274   \n","\n","        Score_8   Score_9  Score_10  ...  Score_12  Score_13  Score_14  \\\n","48421  3.037402  2.926094  2.333342  ...  1.782180  1.739136  1.282862   \n","60415 -2.738926 -2.870982 -3.215358  ... -3.523700 -3.791667 -3.841980   \n","33898 -0.628390 -1.510631 -1.655857  ... -2.012618 -2.378323 -2.555069   \n","23978  3.993275  3.471257  3.449827  ...  2.835068  2.704193  2.618517   \n","2086  -5.531252 -5.750714 -5.792025  ... -6.427528 -6.855747 -7.284554   \n","\n","       Score_15  Score_16  Score_17  Score_18  Score_19  Score_20  Label  \n","48421  1.043963  1.038223  0.876496  0.739709  0.703845  0.416444      0  \n","60415 -3.857994 -4.071139 -4.082572 -4.095625 -4.100740 -4.364736      0  \n","33898 -2.573125 -2.627829 -2.725794 -2.778367 -2.857371 -2.917282      0  \n","23978  2.594410  2.519485  2.493372  2.471543  2.318758  2.287037      0  \n","2086  -7.872125 -8.144029 -9.092268 -9.120149 -9.344419 -9.404174      0  \n","\n","[5 rows x 21 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["non_NLS_feature_df.sample(5)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1357 65590\n"]}],"source":["print(len(NLS_feature_df),len(non_NLS_feature_df))"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# Downsample the non-nuclear proteins and combine with nuclear proteins\n","downsampled_non_nuclear_df = non_NLS_feature_df.sample(n=len(NLS_feature_df), random_state=42)  # Match the number of nuclear samples\n","\n","feature_df = pd.concat([NLS_feature_df,downsampled_non_nuclear_df], axis=0)\n","shuffled_feature_df = feature_df.sample(frac=1, random_state=42).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Binary classification"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neural_network import MLPClassifier\n","\n","\n","from sklearn.metrics import classification_report"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["# define training and further testing data\n","X = shuffled_feature_df.iloc[:,:feature_vec_length]\n","y = shuffled_feature_df.iloc[:,feature_vec_length]\n","\n","further_test_df = non_NLS_feature_df.sample(n=1000, random_state=100)  \n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["# Initialize and train classifier\n","classifier_dict = {'logistic_regression' : LogisticRegression(),\n","                   'support_vector_machine' : SVC(kernel='linear'),\n","                    'decision_tree' : DecisionTreeClassifier(random_state=43),\n","                    'random_forest' : RandomForestClassifier(n_estimators=100, random_state=43),\n","                    'gradient_boosting_machines' : GradientBoostingClassifier(random_state=43),\n","                    'naive_bayes' : GaussianNB(),\n","                    'MLP' : MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, activation='relu', solver='adam', random_state=43)}\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["# Binary classification \n","def train_and_predict(X,y,further_test_df, feature_vec_length, classifier_name):\n","    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)  # 60% training, 40% temp\n","    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # Split temp into 50% test, 50% validation\n","    # Create futher non nuclear data set and make prediction\n","    X_further_test = further_test_df.iloc[:,:feature_vec_length]\n","    y_further_test = further_test_df.iloc[:,feature_vec_length]\n","\n","\n","    classifier = classifier_dict[classifier_name]\n","    classifier.fit(X_train, y_train)\n","\n","    print(f\"The classifier is {classifier_name}\")\n","    # Predict on the validation set    \n","    val_predictions = classifier.predict(X_val)\n","    print(\"Validation Report:\")\n","    print(classification_report(y_val, val_predictions))\n","\n","    # Predict on the test set\n","    test_predictions = classifier.predict(X_test)\n","\n","    # Evaluate the model on the test set\n","    print(\"Test Report:\")\n","    print(classification_report(y_test, test_predictions))\n","\n","    # Predict on the further dataset\n","    further_test_predictions = classifier.predict(X_further_test)\n","\n","    # Evaluate the model on the test set\n","    print(\"Further Test Report:\")\n","    print(classification_report(y_further_test, further_test_predictions))\n","        "]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["The classifier is logistic_regression\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.74      0.72       261\n","           1       0.75      0.72      0.74       282\n","\n","    accuracy                           0.73       543\n","   macro avg       0.73      0.73      0.73       543\n","weighted avg       0.73      0.73      0.73       543\n","\n","Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.71      0.73       285\n","           1       0.70      0.74      0.72       258\n","\n","    accuracy                           0.72       543\n","   macro avg       0.72      0.72      0.72       543\n","weighted avg       0.73      0.72      0.72       543\n","\n","Further Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.71      0.83      1000\n","           1       0.00      0.00      0.00         0\n","\n","    accuracy                           0.71      1000\n","   macro avg       0.50      0.36      0.42      1000\n","weighted avg       1.00      0.71      0.83      1000\n","\n","The classifier is support_vector_machine\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.73      0.73       261\n","           1       0.75      0.74      0.75       282\n","\n","    accuracy                           0.74       543\n","   macro avg       0.74      0.74      0.74       543\n","weighted avg       0.74      0.74      0.74       543\n","\n","Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.69      0.73       285\n","           1       0.69      0.78      0.73       258\n","\n","    accuracy                           0.73       543\n","   macro avg       0.73      0.73      0.73       543\n","weighted avg       0.73      0.73      0.73       543\n","\n","Further Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.69      0.82      1000\n","           1       0.00      0.00      0.00         0\n","\n","    accuracy                           0.69      1000\n","   macro avg       0.50      0.35      0.41      1000\n","weighted avg       1.00      0.69      0.82      1000\n","\n","The classifier is decision_tree\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.70      0.71       261\n","           1       0.73      0.74      0.73       282\n","\n","    accuracy                           0.72       543\n","   macro avg       0.72      0.72      0.72       543\n","weighted avg       0.72      0.72      0.72       543\n","\n","Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.69      0.73       285\n","           1       0.70      0.78      0.74       258\n","\n","    accuracy                           0.73       543\n","   macro avg       0.74      0.74      0.73       543\n","weighted avg       0.74      0.73      0.73       543\n","\n","Further Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.68      0.81      1000\n","           1       0.00      0.00      0.00         0\n","\n","    accuracy                           0.68      1000\n","   macro avg       0.50      0.34      0.41      1000\n","weighted avg       1.00      0.68      0.81      1000\n","\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["The classifier is random_forest\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.72      0.75       261\n","           1       0.76      0.81      0.78       282\n","\n","    accuracy                           0.77       543\n","   macro avg       0.77      0.77      0.77       543\n","weighted avg       0.77      0.77      0.77       543\n","\n","Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.69      0.75       285\n","           1       0.71      0.83      0.77       258\n","\n","    accuracy                           0.76       543\n","   macro avg       0.77      0.76      0.76       543\n","weighted avg       0.77      0.76      0.76       543\n","\n","Further Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.71      0.83      1000\n","           1       0.00      0.00      0.00         0\n","\n","    accuracy                           0.71      1000\n","   macro avg       0.50      0.36      0.42      1000\n","weighted avg       1.00      0.71      0.83      1000\n","\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["The classifier is gradient_boosting_machines\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.68      0.72       261\n","           1       0.73      0.80      0.76       282\n","\n","    accuracy                           0.74       543\n","   macro avg       0.75      0.74      0.74       543\n","weighted avg       0.75      0.74      0.74       543\n","\n","Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.67      0.73       285\n","           1       0.69      0.81      0.74       258\n","\n","    accuracy                           0.74       543\n","   macro avg       0.74      0.74      0.74       543\n","weighted avg       0.74      0.74      0.74       543\n","\n","Further Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.67      0.81      1000\n","           1       0.00      0.00      0.00         0\n","\n","    accuracy                           0.67      1000\n","   macro avg       0.50      0.34      0.40      1000\n","weighted avg       1.00      0.67      0.81      1000\n","\n","The classifier is naive_bayes\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.70      0.73       261\n","           1       0.74      0.78      0.76       282\n","\n","    accuracy                           0.74       543\n","   macro avg       0.74      0.74      0.74       543\n","weighted avg       0.74      0.74      0.74       543\n","\n","Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.78      0.67      0.72       285\n","           1       0.68      0.79      0.73       258\n","\n","    accuracy                           0.72       543\n","   macro avg       0.73      0.73      0.72       543\n","weighted avg       0.73      0.72      0.72       543\n","\n","Further Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.67      0.80      1000\n","           1       0.00      0.00      0.00         0\n","\n","    accuracy                           0.67      1000\n","   macro avg       0.50      0.34      0.40      1000\n","weighted avg       1.00      0.67      0.80      1000\n","\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["The classifier is MLP\n","Validation Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.70      0.72       261\n","           1       0.74      0.78      0.76       282\n","\n","    accuracy                           0.74       543\n","   macro avg       0.74      0.74      0.74       543\n","weighted avg       0.74      0.74      0.74       543\n","\n","Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.66      0.72       285\n","           1       0.68      0.81      0.74       258\n","\n","    accuracy                           0.73       543\n","   macro avg       0.74      0.73      0.73       543\n","weighted avg       0.74      0.73      0.73       543\n","\n","Further Test Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.67      0.80      1000\n","           1       0.00      0.00      0.00         0\n","\n","    accuracy                           0.67      1000\n","   macro avg       0.50      0.33      0.40      1000\n","weighted avg       1.00      0.67      0.80      1000\n","\n"]},{"name":"stderr","output_type":"stream","text":["/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/Users/mingzhang/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["# Binary classification using different classifiers\n","for classifier_name in classifier_dict:\n","    train_and_predict(X,y,further_test_df, feature_vec_length, classifier_name)"]},{"cell_type":"markdown","metadata":{},"source":["## Test on a different dataset"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["      ACC                                       AnnotEncoded  \\\n","0  O75439  3333333333333333333333333333333333333333333330...   \n","1  Q2TBK2  3333333333333333333333333333333333333333333333...   \n","2  Q5VY80  0000000000000000000000000000000000000000000000...   \n","3  Q9BZM6  0000000000000000000000000000000000000000000000...   \n","4  O75489  3333333333333333333333333333333333330000000000...   \n","\n","                                            Sequence Types  Length  \n","0  MAAAAARVVLSSAARRRLWGFSESLLIRGAAGRSLYFGENRLRSTQ...    MT     489  \n","1  MAAAAFAVPRGVQLRVLTERLLRGGVRELLRPRLSGSTPGSERDFS...    MT     268  \n","2  MAAAAIPALLLCLPLLFLLFGWSRARRDDPHSLCYDITVIPKFRPG...   GPI     246  \n","3  MAAAASPAFLLCLPLLHLLSGWSRAGWVDTHCLCYDFIITPKSRPE...   GPI     244  \n","4  MAAAAVARLWWRGILGASALTRGTGRPSVLLLPVRRESAGADTRPT...    MT     264  \n"]}],"source":["# Load a different dataset that contains proteins with different localization signals including nls\n","new_df = pd.read_csv('data/finalized_df_cleaned.csv')\n","print(new_df.head())"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# Clean data\n","cleaned_new_df = remove_sequences(new_df, 'Sequence')"]},{"cell_type":"code","execution_count":188,"metadata":{},"outputs":[],"source":["# def create_scores(df, column_name):\n","\n","#     sequence_scores_list = [pssm.calculate(protein_seq) for protein_seq in df[column_name]]\n","#     return sequence_scores_list\n","\n","from sklearn.preprocessing import OneHotEncoder\n","\n","encoder = OneHotEncoder(categories =[list_standard_amino_acids], sparse_output=False)  # Using sparse=False to get a dense array\n","\n","def create_modified_one_hot_encoding(df, column_name):\n","    modified_one_hot_encoded_list = []\n","\n","    for protein_seq in df[column_name]:\n","        data = np.array(list(protein_seq)).reshape(-1,1)\n","\n","\n","        one_hot_encoded = encoder.fit_transform(data)\n","\n","        # Obtain PSSM scores, and pad or truncate as necessary\n","        pssm_scores = pssm.calculate(protein_seq)\n","        padded_pssm_scores = np.append(pssm_scores, np.zeros(17))\n","        \n","        # Element-wise multiplication of one-hot encoded matrix with PSSM scores\n","        modified_one_hot_encoded = one_hot_encoded * padded_pssm_scores[:len(one_hot_encoded)][:, None]\n","\n","\n","        # Ensure each matrix has exactly 1000 rows\n","        target_length = 1000\n","        current_length = modified_one_hot_encoded.shape[0]\n","        \n","        if current_length < target_length:\n","            # Pad with zeros if fewer than 1000 rows\n","            padding = np.zeros((target_length - current_length, modified_one_hot_encoded.shape[1]))\n","            modified_one_hot_encoded = np.vstack([modified_one_hot_encoded, padding])\n","        else:\n","            # Truncate if more than 1000 rows\n","            modified_one_hot_encoded = modified_one_hot_encoded[:target_length]\n","        # Append the final modified encoding to the list\n","        modified_one_hot_encoded_list.append(modified_one_hot_encoded)\n","\n","    return modified_one_hot_encoded_list\n","\n","\n","def create_one_hot_encoding(df, column_name):\n","    one_hot_encoded_list = []\n","\n","    for protein_seq in df[column_name]:\n","        data = np.array(list(protein_seq)).reshape(-1,1)\n","\n","\n","        one_hot_encoded = encoder.fit_transform(data)\n","\n","\n","        # Ensure each matrix has exactly 1000 rows\n","        target_length = 1000\n","        current_length = one_hot_encoded.shape[0]\n","        \n","        if current_length < target_length:\n","            # Pad with zeros if fewer than 1000 rows\n","            padding = np.zeros((target_length - current_length, one_hot_encoded.shape[1]))\n","            one_hot_encoded = np.vstack([one_hot_encoded, padding])\n","        else:\n","            # Truncate if more than 1000 rows\n","            one_hot_encoded = one_hot_encoded[:target_length]\n","        # Append the final modified encoding to the list\n","        one_hot_encoded_list.append(one_hot_encoded)\n","\n","    return one_hot_encoded_list\n"]},{"cell_type":"code","execution_count":189,"metadata":{},"outputs":[],"source":["modified_one_hot_encoding_list = create_modified_one_hot_encoding(new_df_cleaned, 'Sequence')\n","one_hot_encoding_list = create_one_hot_encoding(new_df_cleaned, 'Sequence')"]},{"cell_type":"code","execution_count":161,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ACC</th>\n","      <th>Encoding</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>O75439</td>\n","      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Q2TBK2</td>\n","      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Q5VY80</td>\n","      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Q9BZM6</td>\n","      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>O75489</td>\n","      <td>[[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      ACC                                           Encoding  Label\n","0  O75439  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n","1  Q2TBK2  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n","2  Q5VY80  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n","3  Q9BZM6  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n","4  O75489  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0"]},"execution_count":161,"metadata":{},"output_type":"execute_result"}],"source":["encoded_new_df = new_df_cleaned [['ACC']].copy()\n","encoded_new_df['Encoding'] = modified_one_hot_encoding_list\n","encoded_new_df['Label'] = new_df_cleaned['Types'].str.contains('NLS', na=False).astype(int)\n","\n","\n","encoded_new_df.head()"]},{"cell_type":"code","execution_count":163,"metadata":{},"outputs":[],"source":["import gzip\n","import pickle\n","\n","with gzip.open('cnn_input_data.pkl.gz', 'wb') as f:\n","    pickle.dump(encoded_new_df, f)\n"]},{"cell_type":"code","execution_count":196,"metadata":{},"outputs":[],"source":["naive_encoded_new_df = pd.DataFrame({'Encoding': one_hot_encoding_list})\n","naive_encoded_new_df['Label'] = new_df_cleaned['Types'].str.contains('NLS', na=False).astype(int)\n","\n","\n","with gzip.open('naive_encoded_cnn_input_data.pkl.gz', 'wb') as f:\n","    pickle.dump(encoded_new_df, f)"]},{"cell_type":"markdown","metadata":{},"source":["# Create testing datasets"]},{"cell_type":"code","execution_count":165,"metadata":{},"outputs":[],"source":["# Load nuclear and non-nuclear protein sequences\n","nuclear_protein_df = pd.read_csv('data_NLS.csv')\n","non_nuclear_proteins_df = pd.read_csv('data_non_nuclear_proteins.csv')"]},{"cell_type":"code","execution_count":173,"metadata":{},"outputs":[],"source":["# Clean data\n","nuclear_protein_df_cleaned = remove_sequences(nuclear_protein_df,'Sequence_y')\n","non_nuclear_proteins_df_cleaned = remove_short_sequences(remove_sequences(non_nuclear_proteins_df, 'Sequence'),length_cutoff)"]},{"cell_type":"code","execution_count":174,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Begin</th>\n","      <th>End</th>\n","      <th>Sequence_x</th>\n","      <th>Length</th>\n","      <th>Sequence_y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Q14738</td>\n","      <td>548</td>\n","      <td>565</td>\n","      <td>KRTVETEAVQMLKDIKKE</td>\n","      <td>18</td>\n","      <td>MPYKLKKEKEPPKVAKCTAKPSSSGKDGGGENTEEAQPQPQPQPQP...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Q13362</td>\n","      <td>416</td>\n","      <td>422</td>\n","      <td>KLKEKLK</td>\n","      <td>7</td>\n","      <td>MLTCNKAGSRMVVDAANSNGPFQPVVLLHIRDVPPADQEKLFIQKL...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Q9NRA8</td>\n","      <td>195</td>\n","      <td>211</td>\n","      <td>RREFGDSKRVFGERRRN</td>\n","      <td>17</td>\n","      <td>MDRRSMGETESGDAFLDLKKPPASKCPHRYTKEELLDIKELPHSKQ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>P42684</td>\n","      <td>658</td>\n","      <td>660</td>\n","      <td>KKR</td>\n","      <td>3</td>\n","      <td>MGQQVGRVGEAPGLQQPQPRGIRGSSAARPSGRRRDPAGRTTETGF...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Q4JIM5</td>\n","      <td>659</td>\n","      <td>661</td>\n","      <td>KKR</td>\n","      <td>3</td>\n","      <td>MGQQVGRVGEAPGLQQPQPRGIRGSSAARPSGRRRDPAGRTADAGF...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       ID  Begin  End          Sequence_x  Length  \\\n","0  Q14738    548  565  KRTVETEAVQMLKDIKKE      18   \n","1  Q13362    416  422             KLKEKLK       7   \n","2  Q9NRA8    195  211   RREFGDSKRVFGERRRN      17   \n","3  P42684    658  660                 KKR       3   \n","4  Q4JIM5    659  661                 KKR       3   \n","\n","                                          Sequence_y  \n","0  MPYKLKKEKEPPKVAKCTAKPSSSGKDGGGENTEEAQPQPQPQPQP...  \n","1  MLTCNKAGSRMVVDAANSNGPFQPVVLLHIRDVPPADQEKLFIQKL...  \n","2  MDRRSMGETESGDAFLDLKKPPASKCPHRYTKEELLDIKELPHSKQ...  \n","3  MGQQVGRVGEAPGLQQPQPRGIRGSSAARPSGRRRDPAGRTTETGF...  \n","4  MGQQVGRVGEAPGLQQPQPRGIRGSSAARPSGRRRDPAGRTADAGF...  "]},"execution_count":174,"metadata":{},"output_type":"execute_result"}],"source":["nuclear_protein_df_cleaned.head()"]},{"cell_type":"code","execution_count":203,"metadata":{},"outputs":[],"source":["# Downsample the non-nuclear proteins \n","\n","downsampled_non_nuclear_df = non_nuclear_proteins_df_cleaned.sample(n=len(nuclear_protein_df_cleaned), random_state= 30)  # Match the number of nuclear samples\n","\n","\n","nls_encoding_list = create_modified_one_hot_encoding(nuclear_protein_df_cleaned, 'Sequence_y')\n","non_nls_encoding_list = create_modified_one_hot_encoding(downsampled_non_nuclear_df, 'Sequence')"]},{"cell_type":"code","execution_count":185,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1357 1357\n"]}],"source":["print(len(nls_encoding_list),len(non_nls_encoding_list))"]},{"cell_type":"code","execution_count":186,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                            Encoding  Label\n","0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n","1  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n","2  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n","3  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n","4  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n","5  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0\n","6  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n","7  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n","8  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n","9  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n"]}],"source":["encoded_nls_df = pd.DataFrame({'Encoding' : nls_encoding_list})\n","encoded_nls_df['Label'] = 1\n","\n","encoded_non_nls_df = pd.DataFrame({'Encoding' : non_nls_encoding_list})\n","encoded_non_nls_df['Label'] = 0\n","\n","encoded_all_df = pd.concat([encoded_nls_df, encoded_non_nls_df], axis=0)\n","shuffled_encoded_all_df = encoded_all_df.sample(frac=1, random_state=50).reset_index(drop=True)\n","\n","print(shuffled_encoded_all_df.head(10))\n"]},{"cell_type":"code","execution_count":187,"metadata":{},"outputs":[],"source":["import gzip\n","import pickle\n","\n","with gzip.open('testing_data.pkl.gz', 'wb') as f:\n","    pickle.dump(shuffled_encoded_all_df , f)\n"]},{"cell_type":"code","execution_count":204,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                            Encoding  Label\n","0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0\n","1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      1\n","2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0\n","3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0\n","4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      1\n","5  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0\n","6  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      1\n","7  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      1\n","8  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0\n","9  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0\n"]}],"source":["nls_naive_encoding_list = create_one_hot_encoding(nuclear_protein_df_cleaned, 'Sequence_y')\n","non_nls_naive_encoding_list = create_one_hot_encoding(downsampled_non_nuclear_df, 'Sequence')\n","\n","naive_encoded_nls_df = pd.DataFrame({'Encoding' : nls_naive_encoding_list})\n","naive_encoded_nls_df['Label'] = 1\n","\n","naive_encoded_non_nls_df = pd.DataFrame({'Encoding' : non_nls_naive_encoding_list})\n","naive_encoded_non_nls_df['Label'] = 0\n","\n","naive_encoded_all_df = pd.concat([naive_encoded_nls_df, naive_encoded_non_nls_df], axis=0)\n","shuffled_naive_encoded_all_df = naive_encoded_all_df.sample(frac=1, random_state=50).reset_index(drop=True)\n","\n","print(shuffled_naive_encoded_all_df.head(10))\n","\n"]},{"cell_type":"code","execution_count":205,"metadata":{},"outputs":[],"source":["with gzip.open('testing_data_naive_encoded.pkl.gz', 'wb') as f:\n","    pickle.dump(shuffled_naive_encoded_all_df , f)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNCg1LEz2/qWUJHxlCv7o/G","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
