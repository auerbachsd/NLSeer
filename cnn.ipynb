{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check if the GPU is available and output its name\n",
        "if tf.test.gpu_device_name():\n",
        "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
        "else:\n",
        "    print(\"Please install GPU version of TF\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2Nmk7yu26EX",
        "outputId": "2f3d7e15-4dd0-45f0-fcd6-1c9cb5c9c726"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
            "Default GPU Device: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Confirm that GPU is being used\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZfTXptp3IcU",
        "outputId": "4228a1e4-e7bf-4d70-cd59-216bc30616b5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn(input_shape):\n",
        "    # Input layer\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Convolutional layers with different kernel sizes\n",
        "    conv_layers = []\n",
        "    kernel_sizes = [1, 3, 5, 9, 15, 21]\n",
        "    for size in kernel_sizes:\n",
        "        conv = Conv1D(filters=64, kernel_size=size, activation='relu', padding='same')(inputs)\n",
        "        conv_layers.append(conv)\n",
        "\n",
        "    # Concatenate all convolutional layers\n",
        "    concatenated = concatenate(conv_layers, axis=-1)\n",
        "\n",
        "    # Final convolutional layer\n",
        "    final_conv = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(concatenated)\n",
        "\n",
        "    # Max pooling layer\n",
        "    pooled = MaxPooling1D(pool_size=5)(final_conv)\n",
        "\n",
        "    # Dropout layer\n",
        "    dropped = Dropout(rate=0.25)(pooled)\n",
        "\n",
        "    # Flatten layer\n",
        "    flatten = Flatten()(dropped)\n",
        "\n",
        "    # Dense layer\n",
        "    dense = Dense(64, activation='relu')(flatten)\n",
        "\n",
        "      # Output layer for binary classification\n",
        "    output = Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model"
      ],
      "metadata": {
        "id": "epbJ29-74cT_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN2Zqp0P2EKL",
        "outputId": "d345d25e-6b9d-4d73-ef89-d4e6ed557963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         ACC                                           Encoding  Label\n",
            "0     O75439  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "1     Q2TBK2  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "2     Q5VY80  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "3     Q9BZM6  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "4     O75489  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "...      ...                                                ...    ...\n",
            "2947  Q96CK0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "2948  Q96CK0  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "2949  Q24JY4  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "2950  O43257  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "2951  Q8R331  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "\n",
            "[2951 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Loading the compressed pickle file\n",
        "with gzip.open('cnn_input_data.pkl.gz', 'rb') as f:\n",
        "    df = pickle.load(f)\n",
        "\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.stack(df['Encoding'].values)\n",
        "y = df['Label'].values.astype('int')  # Ensure labels are integers (0 or 1)\n",
        "\n",
        "# K-Fold Cross-Validation setup\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=50)\n",
        "fold = 0\n",
        "accuracies = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    fold += 1\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Build and compile CNN model\n",
        "    input_shape = (1000, 20)\n",
        "    cnn_model = build_cnn(input_shape)\n",
        "    cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "    # Train CNN model\n",
        "    history = cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "    # Extract features for XGBoost\n",
        "    feature_layer_model = Model(inputs=cnn_model.input, outputs=cnn_model.layers[-2].output)\n",
        "    X_train_features = feature_layer_model.predict(X_train)\n",
        "    X_test_features = feature_layer_model.predict(X_test)\n",
        "\n",
        "    # Train XGBoost on extracted features\n",
        "    xgb_model = xgb.XGBClassifier()\n",
        "    xgb_model.fit(X_train_features, y_train)\n",
        "\n",
        "    # Predict using XGBoost\n",
        "    y_pred_xgb = xgb_model.predict(X_test_features)\n",
        "\n",
        "    # Calculate and store accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "    accuracies.append(accuracy)\n",
        "    print(f\"Fold {fold}, Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "# Average accuracy across all folds\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(f\"Average Accuracy: {average_accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umEClQ0Y40a8",
        "outputId": "03af1cf9-aed1-4e44-eaff-46267b8242e6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "59/59 [==============================] - 4s 25ms/step - loss: 0.8946 - accuracy: 0.6690 - val_loss: 0.8005 - val_accuracy: 0.4958\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.4413 - accuracy: 0.7807 - val_loss: 0.7431 - val_accuracy: 0.6801\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.2985 - accuracy: 0.8718 - val_loss: 0.5154 - val_accuracy: 0.8008\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.2167 - accuracy: 0.9211 - val_loss: 1.1578 - val_accuracy: 0.4534\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.1933 - accuracy: 0.9269 - val_loss: 0.6599 - val_accuracy: 0.7352\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 1s 20ms/step - loss: 0.1224 - accuracy: 0.9571 - val_loss: 0.6967 - val_accuracy: 0.7267\n",
            "74/74 [==============================] - 1s 6ms/step\n",
            "19/19 [==============================] - 0s 5ms/step\n",
            "Fold 1, Accuracy: 92.72%\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 4s 34ms/step - loss: 0.8208 - accuracy: 0.6758 - val_loss: 0.8678 - val_accuracy: 0.2875\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.4388 - accuracy: 0.7648 - val_loss: 0.7776 - val_accuracy: 0.5624\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.3556 - accuracy: 0.8427 - val_loss: 0.7068 - val_accuracy: 0.6173\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.2580 - accuracy: 0.9073 - val_loss: 1.2150 - val_accuracy: 0.4482\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.2059 - accuracy: 0.9147 - val_loss: 0.5836 - val_accuracy: 0.7590\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.1532 - accuracy: 0.9407 - val_loss: 1.2279 - val_accuracy: 0.5856\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.0970 - accuracy: 0.9661 - val_loss: 0.7088 - val_accuracy: 0.7315\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0871 - accuracy: 0.9719 - val_loss: 1.2419 - val_accuracy: 0.5962\n",
            "74/74 [==============================] - 1s 5ms/step\n",
            "19/19 [==============================] - 0s 17ms/step\n",
            "Fold 2, Accuracy: 89.49%\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 4s 27ms/step - loss: 0.9691 - accuracy: 0.6743 - val_loss: 0.6925 - val_accuracy: 0.5603\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.4076 - accuracy: 0.8077 - val_loss: 0.6921 - val_accuracy: 0.6173\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.2471 - accuracy: 0.8983 - val_loss: 0.5927 - val_accuracy: 0.6765\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.1636 - accuracy: 0.9349 - val_loss: 0.5912 - val_accuracy: 0.7061\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.1069 - accuracy: 0.9656 - val_loss: 0.8306 - val_accuracy: 0.6469\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.0652 - accuracy: 0.9804 - val_loss: 1.0024 - val_accuracy: 0.6723\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.0671 - accuracy: 0.9783 - val_loss: 1.5432 - val_accuracy: 0.4715\n",
            "74/74 [==============================] - 0s 5ms/step\n",
            "19/19 [==============================] - 0s 5ms/step\n",
            "Fold 3, Accuracy: 92.03%\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 4s 28ms/step - loss: 0.8937 - accuracy: 0.6425 - val_loss: 0.7770 - val_accuracy: 0.3932\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 1s 17ms/step - loss: 0.4730 - accuracy: 0.7579 - val_loss: 0.6943 - val_accuracy: 0.5772\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.3368 - accuracy: 0.8633 - val_loss: 0.5899 - val_accuracy: 0.7505\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.1891 - accuracy: 0.9296 - val_loss: 0.9941 - val_accuracy: 0.5137\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.1420 - accuracy: 0.9454 - val_loss: 0.8212 - val_accuracy: 0.6892\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.0954 - accuracy: 0.9666 - val_loss: 1.3104 - val_accuracy: 0.5349\n",
            "74/74 [==============================] - 0s 5ms/step\n",
            "19/19 [==============================] - 0s 5ms/step\n",
            "Fold 4, Accuracy: 92.71%\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 4s 28ms/step - loss: 0.5987 - accuracy: 0.7331 - val_loss: 0.4825 - val_accuracy: 0.7780\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.2204 - accuracy: 0.9153 - val_loss: 0.4291 - val_accuracy: 0.8414\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 1s 19ms/step - loss: 0.0813 - accuracy: 0.9772 - val_loss: 0.6912 - val_accuracy: 0.7653\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.0490 - accuracy: 0.9868 - val_loss: 0.9128 - val_accuracy: 0.6892\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.0516 - accuracy: 0.9852 - val_loss: 0.4616 - val_accuracy: 0.8393\n",
            "74/74 [==============================] - 1s 5ms/step\n",
            "19/19 [==============================] - 0s 5ms/step\n",
            "Fold 5, Accuracy: 89.83%\n",
            "Average Accuracy: 91.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the compressed pickle file\n",
        "with gzip.open('testing_data.pkl.gz', 'rb') as f:\n",
        "    test_df = pickle.load(f)\n",
        "\n",
        "print(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqwlsFPAHYPt",
        "outputId": "34dd2a3d-3e50-4633-b8e3-9cf4c826302b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Encoding  Label\n",
            "0     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "1     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "2     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "3     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "4     [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      1\n",
            "...                                                 ...    ...\n",
            "2709  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "2710  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "2711  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "2712  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "2713  [[-0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0...      0\n",
            "\n",
            "[2714 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.stack(test_df['Encoding'].values)\n",
        "y_test = test_df['Label'].values.astype('int')  # Ensure labels are integers (0 or 1)\n",
        "\n",
        "\n",
        "\n",
        "X_test_features = feature_layer_model.predict(X_test)\n",
        "\n",
        "xgb_model.fit(X_train_features, y_train)\n",
        "\n",
        "# Predict using XGBoost\n",
        "y_pred_xgb = xgb_model.predict(X_test_features)\n",
        "\n",
        "# Calculate and store accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "print(f\"Accuracy: {accuracy:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gue0ue2y2fNm",
        "outputId": "5e53bb17-8c47-40c7-d99c-1eb2fe898b99"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85/85 [==============================] - 1s 6ms/step\n",
            "Accuracy: 73.62%\n"
          ]
        }
      ]
    }
  ]
}